<?xml version="1.0" encoding="UTF-8"?>
<!--

    DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS HEADER.

    Copyright (c) 2011-2012 Oracle and/or its affiliates. All rights reserved.

    The contents of this file are subject to the terms of either the GNU
    General Public License Version 2 only ("GPL") or the Common Development
    and Distribution License("CDDL") (collectively, the "License").  You
    may not use this file except in compliance with the License.  You can
    obtain a copy of the License at
    https://glassfish.dev.java.net/public/CDDL+GPL_1_1.html
    or packager/legal/LICENSE.txt.  See the License for the specific
    language governing permissions and limitations under the License.

    When distributing the software, include this License Header Notice in each
    file and include the License file at packager/legal/LICENSE.txt.

    GPL Classpath Exception:
    Oracle designates this particular file as subject to the "Classpath"
    exception as provided by Oracle in the GPL Version 2 section of the License
    file that accompanied this code.

    Modifications:
    If applicable, add the following below the License Header, with the fields
    enclosed by brackets [] replaced by your own identifying information:
    "Portions Copyright [year] [name of copyright owner]"

    Contributor(s):
    If you wish your version of this file to be governed by only the CDDL or
    only the GPL Version 2, indicate your decision by adding "[Contributor]
    elects to include this software in this distribution under the [CDDL or GPL
    Version 2] license."  If you don't indicate a single choice of license, a
    recipient has the option to distribute your version of this file under
    either the CDDL, the GPL Version 2 or to extend the choice of license to
    its licensees as provided above.  However, if you add GPL Version 2 code
    and therefore, elected the GPL Version 2 license, then the option applies
    only if the new code is made subject to such option by the copyright
    holder.

-->
<section version="5.0" xml:id="core-config"
         xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:svg="http://www.w3.org/2000/svg"
         xmlns:m="http://www.w3.org/1998/Math/MathML"
         xmlns:html="http://www.w3.org/1999/xhtml"
         xmlns:db="http://docbook.org/ns/docbook">
  <title>Core Configuration</title>

  <para>The primary points of configuration of the core framework are that of
  the Transport instances and their associated thread pools. The ability to
  configure both entities is possible via the NIOTransportBuilder.</para>

  <section xml:id="transport-config">
    <title>Transport Configuration</title>

    <para>Just as there are concrete NIOTransport implementations for TCP and
    UDP, so too are there two concrete NIOTransportBuilder implementations.
    Each NIOTransportBuilder implementation exposes configurable features
    unique to each transport. The following describes configuration properties
    common to all NIOTransports and then describes the properties for the TCP
    and UDP NIOTransport implementations.</para>

    <table>
      <title>NIOTransportBuilder Properties</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry>workerThreadPoolConfig</entry>

            <entry>This property exposes a ThreadPoolConfig instance that
            allows configuration of the worker thread pool used by the
            transport that will be constructed by this builder. Note:
            depending on the IOStrategy being used, this value may be
            null.</entry>
          </row>

          <row>
            <entry>kernelThreadPoolConfig</entry>

            <entry>This propery exposes a ThreadPoolConfig instance that
            allows configuration of the kernel thread pool used by the
            transport that will be constructed by this builder.</entry>
          </row>

          <row>
            <entry>IOStrategy</entry>

            <entry>Sets the IOStrategy that will be used by this transport.
            Note that changing this value before the transport has been
            started may have an impact on the return value of the
            workerThreadPoolConfig property. If no value is explicitly set,
            the WorkerThreadIOStrategy will be employed. See the section on
            <link xlink:href="iostrategies.xml"
            xml:id="ios001">IOStrategies</link> for specifics on each concrete
            IOStrategy included with Grizzly @project.version@.</entry>
          </row>

          <row>
            <entry>memoryManager</entry>

            <entry>Sets the MemoryManager to be used by this transport. If no
            value is explicitly set, the MemoryManager used will be the
            NIOTransportBuilder.DEFAULT_MEMORY_MANAGER. See the section on
            <link xlink:href="memory.xml" xml:id="mem001">Memory
            Management</link> for specifics on the MemoryManager
            system.</entry>
          </row>

          <row>
            <entry>selectorHandler</entry>

            <entry>Sets the SelectorHandler to be used by this transport. If
            no value is explicitly set, the SelectorHandler used wil be the
            NIOTransportBuilder.DEFAULT_SELECTOR_HANDLER. See the section on
            <link xlink:href="transports-connections.xml"
            xml:id="tc001">Transports and Connections</link> for specifics on
            the SelectorHandler.</entry>
          </row>

          <row>
            <entry>selectionKeyHandler</entry>

            <entry>Sets the SelectionKeyHandler to be used by this transport.
            If no value is explicitly set, the SelectionKeyHandler used will
            be the NIOTransportBuilder.DEFAULT_SELECTION_KEY_HANDLER. See the
            section on <link xlink:href="transports-connections.xml"
            xml:id="tc002">Transports and Connections</link> for specifics on
            the SelectionKeyHandler.</entry>
          </row>

          <row>
            <entry>attributeBuilder</entry>

            <entry>Sets the AttributeBuilder to be used by this transport. If
            no value is explicitly set, the AttributeBuilder used will be the
            NIOTransportBuilder.DEFAULT_ATTRIBUTE_BUILDER.</entry>
          </row>

          <row>
            <entry>NIOChannelDistributor</entry>

            <entry>Sets the NIOChannelDistributor used by this transport. See
            the section on <link xlink:href="transports-connections.xml?"
            xml:id="tc003">Transports and Connections</link> for specifics on
            the NIOChannelDistributor.</entry>
          </row>

          <row>
            <entry>processor</entry>

            <entry>Sets the Processor used by this transport.</entry>
          </row>

          <row>
            <entry>processorSelector</entry>

            <entry>Sets the ProcessorSelector used by this transport.</entry>
          </row>

          <row>
            <entry>readBufferSize</entry>

            <entry>Sets the size of the Buffer that will be allocated,
            per-connection, to read incoming data.</entry>
          </row>

          <row>
            <entry>writeBuffersSize</entry>

            <entry>Sets the size of the Buffer that will be applicated,
            per-connection, to write outgoing data.</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <table>
      <title>TCPNIOTransportBuilder Properties</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry>clientSocketSoTimeout</entry>

            <entry>Enable/disable SO_TIMEOUT with the specified timeout, in
            milliseconds (client mode).</entry>
          </row>

          <row>
            <entry>connectionTimeout</entry>

            <entry>Time in milliseconds for how long establishing a connection
            can take before the operation times out.</entry>
          </row>

          <row>
            <entry>keepAlive</entry>

            <entry>Enable/disable SO_KEEPALIVE.</entry>
          </row>

          <row>
            <entry>linger</entry>

            <entry>Enable/disable SO_LINGER with the specified linger time in
            seconds. The maximum timeout value is platform specific. The
            setting only affects socket close.</entry>
          </row>

          <row>
            <entry>reuseAddress</entry>

            <entry>Enable/disable the SO_REUSEADDR socket option. When a TCP
            connection is closed the connection may remain in a timeout state
            for a period of time after the connection is closed (typically
            known as the TIME_WAIT state or 2MSL wait state). For applications
            using a well known socket address or port it may not be possible
            to bind a socket to the required SocketAddress if there is a
            connection in the timeout state involving the socket address or
            port.</entry>
          </row>

          <row>
            <entry>serverConnectionBacklog</entry>

            <entry>Specifies the maximum pending connection queue
            length.</entry>
          </row>

          <row>
            <entry>serverSocketSoTimeout</entry>

            <entry>Enable/disable SO_TIMEOUT with the specified timeout, in
            milliseconds (server mode).</entry>
          </row>

          <row>
            <entry>tcpNoDelay</entry>

            <entry>Enable/disable TCP_NODELAY (disable/enable Nagle's
            algorithm).</entry>
          </row>

          <row>
            <entry>temporarySelectorIO</entry>

            <entry>Allows the specification of a TemporarySelectorIO instance
            to aid in the simulation of blocking IO.</entry>
          </row>

          <row>
            <entry>optimizedForMultiplexing</entry>

            <entry>Controlls the behavior of writing to a connection. If
            enabled, then all writes regardless if the current thread can
            write directly to the connection or not, will be passed to the
            async write queue. When the write actually occurs, the transport
            will attempt to write as much content from the write queue as
            possible. This option is disabled by default.</entry>
          </row>

          <row>
            <entry>maxAsyncWriteQueueSizeInBytes</entry>

            <entry>Specifies the size, in bytes, of the async write queue on a
            per-connection basis. If not specified, the value will be
            configured to be four times the size of the system's socket write
            buffer size. Setting this value to -1 will allow the queue to be
            unbounded.</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <table>
      <title>UDPNIOTransportBuilder Properties</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry>connectionTimeout</entry>

            <entry>Time in milliseconds for how long establishing a connection
            can take before the operation times out.</entry>
          </row>

          <row>
            <entry>reuseAddress</entry>

            <entry>Enable/disable the SO_REUSEADDR socket option. When a TCP
            connection is closed the connection may remain in a timeout state
            for a period of time after the connection is closed (typically
            known as the TIME_WAIT state or 2MSL wait state). For applications
            using a well known socket address or port it may not be possible
            to bind a socket to the required SocketAddress if there is a
            connection in the timeout state involving the socket address or
            port.</entry>
          </row>

          <row>
            <entry>temporarySelectorIO</entry>

            <entry>Allows the specification of a TemporarySelectorIO instance
            to aid in the simulation of blocking IO.</entry>
          </row>
        </tbody>
      </tgroup>
    </table>
  </section>

  <section xml:id="threadpool-config">
    <title>Thread Pool Configuration</title>

    <para>Grizzly's thread pool configuration is managed by the
    ThreadPoolConfig object:</para>

    <table>
      <title>ThreadPoolConfig Properties</title>

      <tgroup cols="2">
        <tbody>
          <row>
            <entry>queue</entry>

            <entry>The task Queue implementation to be used.</entry>
          </row>

          <row>
            <entry>queueLimit</entry>

            <entry>The maximum number of pending tasks that may be
            queued.</entry>
          </row>

          <row>
            <entry>threadFactory</entry>

            <entry>The ThreadFactory that the pool will use to create new
            Threads.</entry>
          </row>

          <row>
            <entry>poolName</entry>

            <entry>The name of this thread pool.</entry>
          </row>

          <row>
            <entry>priority</entry>

            <entry>The priority to be assigned to each thread. This will
            override any priority assigned by the specified
            ThreadFactory.</entry>
          </row>

          <row>
            <entry>corePoolSize</entry>

            <entry>The initial number of threads that will be present with the
            thread pool is created.</entry>
          </row>

          <row>
            <entry>maxPoolSize</entry>

            <entry>The maximum number threads that may be maintained by this
            thread pool.</entry>
          </row>

          <row>
            <entry>keepAliveTime</entry>

            <entry>The maximum time a thread may be allowed to run. Custom
            time units can be used.</entry>
          </row>
        </tbody>
      </tgroup>
    </table>

    <para>The thread pool configuration is fairly straight forward. However,
    it should be noted that Grizzly, internally, has several thread pool
    implementations: SyncThreadPool, FixedThreadPool, and
    QueueLimitedThreadPool. Which implementation is chosen is based on the
    configuration. The following sections describe each of the thread pool
    implementations.</para>

    <section>
      <title>FixedThreadPool</title>

      <para>This pool will be selected when the queueLimit property is less
      than zero, and the max and core pool sizes are the same. The
      FixedThreadPool has no synchronization when executing tasks, so it
      offers better performance.</para>
    </section>

    <section>
      <title>QueueLimitedThreadPool</title>

      <para>This pool will be selected when the queueLimit property is greater
      than zero, and the max and core pool sizes are the same. The
      QueueLimitedThreadPool is an extension of the FixedThreadPool, so if
      offers the same benefits of the FixedThreadPool without having an
      unbounded task queue.</para>
    </section>

    <section>
      <title>SyncThreadPool</title>

      <para>This pool will be selected when none of the criteria for the other
      thread pools apply. This thread pool does have synchronization to have
      precise control over the decision of thread creation.</para>
    </section>
  </section>

  <section>
    <title>Examples</title>

    <para>Here are some examples of using the TCPNIOTransportBuilder to
    configure the Transport and/or thread pool.</para>

    <programlisting language="java" xml:space="preserve">final TCPNIOTransportBuilder builder = TCPNIOTranportBuilder.newInstance(); 
final TCPNIOTransport transport = builder.build(); </programlisting>

    <para>Creates a new TCPNIOTransport using all default configuration
    values.</para>

    <programlisting language="java">final TCPNIOTransportBuilder builder = TCPNIOTransportBuilder.newInstance(); 
final TCPNIOTransport transport = builder.setIOStrategy(SameThreadIOStrategy.getInstance()).setTcpNoDelay(true).build();     </programlisting>

    <para>Creates a new TCPNIOTransport instance using the
    SameThreadIOStrategy, and tcp-no-delay set to true. Note that
    configuration calls can be chained.</para>

    <programlisting language="java">final TCPNIOTransportBuilder builder = TCPNIOTransportBuilder.newInstance(); 
final ThreadPoolConfig config = builder.getWorkerThreadPoolConfig(); 
config.setCorePoolSize(5).setMaxPoolSize(5).setQueueLimit(-1); 
final TCPNIOTransport transport = builder.build(); </programlisting>

    <para>This example will configure the TCPNIOTransport to use the
    FixedThreadPool implementation due to the fact that there is no queue
    limit and the core and max pool sizes are the same.</para>
  </section>
</section>
