<?xml version="1.0" encoding="UTF-8"?>
<section version="5.0" xml:id="memory" xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:svg="http://www.w3.org/2000/svg"
         xmlns:m="http://www.w3.org/1998/Math/MathML"
         xmlns:html="http://www.w3.org/1999/xhtml"
         xmlns:db="http://docbook.org/ns/docbook">
  <title>Memory Management</title>

  <section>
    <title>Overview</title>

    <para>Grizzly 2.0 introduces a new subsystem to inprove memory mamangement
    within the runtime. This subsystem is comprised of three main
    artifacts:</para>

    <itemizedlist>
      <listitem>
        <para>Buffers</para>
      </listitem>

      <listitem>
        <para>Thread local memory pools</para>
      </listitem>

      <listitem>
        <para>MemoryManager as a factory of sorts using the buffers and thread
        local pools</para>
      </listitem>
    </itemizedlist>

    <para>whose primary purpose is to speed up memory allocation and, when
    possible, provide for memory re-use.</para>

    <para>The following sections will describe these concepts in
    detail.</para>
  </section>

  <section>
    <title>MemoryManager</title>

    <para>The <emphasis>MemoryManager</emphasis> is the main interface for
    allocating/deallocating <emphasis>Buffer</emphasis> instances:</para>

    <programlisting language="java">public interface MemoryManager&lt;E extends Buffer&gt;
        extends JmxMonitoringAware&lt;MemoryProbe&gt; {
    /**
     * Allocates a {@link Buffer} of the required size.
     *
     * @param size {@link Buffer} size to be allocated.
     * @return allocated {@link Buffer}.
     */
    public E allocate(int size);

    /**
     * Allocates {@link Buffer} at least of the provided size.
     * This could be useful for usecases like Socket.read(...), where
     * we're not sure how many bytes are available, but want to read as
     * much as possible.
     *
     * @param size the min {@link Buffer} size to be allocated.
     * @return allocated {@link Buffer}.
     */
    public E allocateAtLeast(int size);
    
    /**
     * Reallocate {@link Buffer} to a required size.
     * Implementation may choose the way, how reallocation could be done, either
     * by allocating new {@link Buffer} of required size and copying old
     * {@link Buffer} content there, or perform more complex logic related to
     * memory pooling etc.
     *
     * @param oldBuffer old {@link Buffer} to be reallocated.
     * @param newSize new {@link Buffer} required size.
     * @return reallocated {@link Buffer}.
     */
    public E reallocate(E oldBuffer, int newSize);

    /**
     * Release {@link Buffer}.
     * Implementation may ignore releasing and let JVM Garbage collector to take
     * care about the {@link Buffer}, or return {@link Buffer} to pool, in case
     * of more complex &lt;tt&gt;MemoryManager&lt;/tt&gt; implementation.
     *
     * @param buffer {@link Buffer} to be released.
     */
    public void release(E buffer);</programlisting>

    <para>There is typically a single <emphasis>MemoryManager</emphasis>
    servicing all transports defined within the Grizzly runtime. This
    <emphasis>MemoryManager</emphasis> can be obtained by calling:</para>

    <programlisting language="java">TransportFactory.getInstance().getDefaultMemoryManager();</programlisting>

    <para>Conversely, custom <emphasis>MemoryManager</emphasis>
    implementations may be made available to the application by
    calling:</para>

    <programlisting language="java">TransportFactory.getInstance().setDefaultMemoryManager(MemoryManager defaultMemoryManager);</programlisting>

    <para>The <emphasis>MemoryManager</emphasis> instance exposed by the
    <emphasis>TransportFactory</emphasis> can be obtained without calling the
    <emphasis>TransportFactory</emphasis> directly as it will be available on
    the <emphasis>NIOTransport</emphasis> being used by the
    application.</para>

    <para>Grizzly 2.0 includes two <emphasis>MemoryManager</emphasis>
    implementations: <emphasis>HeapMemoryManager</emphasis> and
    <emphasis>ByteBufferManager</emphasis>. By default, the Grizzly runtime
    will use the <emphasis>HeapMemoryManager</emphasis>, however if a Grizzly
    application requires Direct ByteBuffer access, then the
    <emphasis>ByteBufferManager</emphasis> can be used.</para>

    <section>
      <title>ByteBufferManager</title>

      <para>The <emphasis>ByteBufferManager</emphasis> implementation vends
      Buffers that wrap JDK ByteBuffer instances. </para>

      <figure>
        <title>ByteBufferManager UML Diagram</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="../images/coreframework/bbmmanager-uml.svgz"
                       scale="40"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>
    </section>

    <section>
      <title>HeapMemoryManager</title>

      <para>Developers may wonder why Grizzly have a
      <emphasis>HeapMemoryManager</emphasis> when the
      <emphasis>ByteBufferManager</emphasis> can be used with both direct and
      heap ByteBuffers. The main reason is cheaper allocation performance as
      well as making operations such a trim() and shrink() (covered later in
      this section) cheap as well.</para>

      <figure>
        <title>HeapMemoryManager UML Diagram</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="../images/coreframework/heapmmanager-uml.svgz"
                       scale="40"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>
    </section>

    <section>
      <title>ThreadLocal Memory Pools</title>

      <para>ThreadLocal memory pools provide the ability to allocate memory
      without any synchronization costs. Both the
      <emphasis>ByteBufferManager</emphasis> and
      <emphasis>HeapMemoryManager</emphasis> use such pools. Note that it's
      not required that a custom <emphasis>MemoryManager</emphasis> use such
      pools, however, if said <emphasis>MemoryManager</emphasis> implements
      the <emphasis>ThreadLocalPoolProvider</emphasis> interface, then a
      <emphasis>ThreadLocalPool</emphasis> implementation must be provided.
      The <emphasis>ThreadLocalPool</emphasis> implementation will be created
      and passed to each thread being maintained by Grizzly's managed
      threads.</para>
    </section>

    <section>
      <title>Memory Manager and ThreadLocal Memory Pools Working
      Together</title>

      <para>The following provides a flow diagram of how an allocation request
      to a <emphasis>MemoryManager</emphasis> with a
      <emphasis>ThreadLocalPool</emphasis> would typically work:</para>

      <figure>
        <title>MemoryManager Allocation Request Flow</title>

        <mediaobject>
          <imageobject>
            <imagedata fileref="../images/coreframework/mmflow.svgz"
                       scale="50"></imagedata>
          </imageobject>
        </mediaobject>
      </figure>
    </section>
  </section>

  <section>
    <title>Buffers</title>

    <para>Grizzly 2.0 provides several buffers for developers to leverage when
    creating applications. These <emphasis>Buffer</emphasis> implementations
    offer features not available when using the JDK's ByteBuffer.</para>

    <section>
      <title>Buffer</title>

      <para>The <emphasis>Buffer</emphasis> is essentially the analogue to the
      JDK's ByteBuffer. It offers the same set of methods for:</para>

      <itemizedlist>
        <listitem>
          <para>Pushing/pulling data to/from the
          <emphasis>Buffer</emphasis>.</para>
        </listitem>

        <listitem>
          <para>Methods for accessing or manipulating the
          <emphasis>Buffer's</emphasis> position, limit, and capacity.</para>
        </listitem>
      </itemizedlist>

      <para>In addition to offering familar semantics to ByteBuffer, the
      following features are available:</para>

      <itemizedlist>
        <listitem>
          <para>Splitting, trimming, and shrinking.</para>
        </listitem>

        <listitem>
          <para>Prepending another <emphasis>Buffer's</emphasis> content to
          the current Buffer.</para>
        </listitem>

        <listitem>
          <para>Converting the <emphasis>Buffer</emphasis> to a ByteBuffer or
          ByteBuffer[].</para>
        </listitem>

        <listitem>
          <para>Converting <emphasis>Buffer</emphasis> content to a
          String.</para>
        </listitem>
      </itemizedlist>

      <para>Please see the javadocs for further details on
      <emphasis>Buffer</emphasis>.</para>
    </section>

    <section>
      <title>CompositeBuffer</title>

      <para>The <emphasis>CompositeBuffer</emphasis> is another
      <emphasis>Buffer</emphasis> implementation which allows appending of
      <emphasis>Buffer</emphasis> instances. The CompositeBuffer maintains a
      virtual position, limit, and capacity based on the
      <emphasis>Buffers</emphasis> that have been appended and can be treated
      as a simple <emphasis>Buffer</emphasis> instance. </para>

      <para>Please see the javadocs for further details on
      <emphasis>CompositeBuffer</emphasis>.</para>
    </section>
  </section>
</section>
